### General description
\label{typing::lambda-calculus::general-description}

In this part, we consider a restriction of the language to a subset of itself
consisting of a lambda-calculus with typecase (i.e. we exclude lists and
records and all the related operations).

The type-system is divided into two parts: an "inference" system and a "check"
one.
The first one corresponds to classical bottom-up type inference while the
second one is a top-down system which doesn't do any inference but only tries
to check that an expression accepts a given type.
This double system is an extension of the use of type annotations in inference
algorithms which allows using them in a non-local way. This result may be
obtained in many languages by simply preprocessing the code and trying to
propagate the type annotations (that's for example what OCaml does in order not
to enforce the programmer to directly annotate the return type of a
pattern-matching on a GADT, but let him simply annotate for example the
top-level expression).
In Nix-light however, the presence of union and intersection types makes
certain expressions impossible to annotate because they will be given several
different types under different environments.

For example, let's consider the following expression:

```
let f =
  λcond.λx.
    (_ = cond tin true) ? x + 1 : not x
in f
```

We wish to give it the type `(true -> Int -> Int) AND (false -> Bool -> Bool)`.
This means that `x` must have the type `Int` if `cond` is `true`, and `Bool`
otherwise.
It is thus impossible to annotate − except by the type `Int AND Bool` which
equals `Empty`, or by the gradual type.

However, the check type-system allows to check − if we annotate `f` with the
type `(true -> Int -> Int) AND (false -> Bool -> Bool)` − to check that the
expression indeed admits both types `true -> Int -> Int` and `false -> Bool ->
Bool` (and thus the intersection of both).

### Typing of patterns

For the restriction of the language that we consider here, the only possible
patterns are `<var>` and `<var:τ`.

\newcommand{\accept}[1]{\lbag{}#1\rbag{}}
\newcommand{\tmatch}[2]{\sfrac{#2}{#1}}

We define two operators $\accept{p}$ and $\tmatch{\τ}{p}$ which corresponds
respectively to the type accepted by a pattern $p$ and the typing environment
generated by the matching of a type $\τ$ against the pattern $p$ by:

\begin{align*}
  \accept{x} &= \grad \\
  \accept{x:\tau} &= \tau
\end{align*}

and

\begin{align*}
  \tmatch{\tau}{x} &= x : \tau \\
  \tmatch{\sigma}{x:\tau} &= \sigma \cap \tau
\end{align*}


By default (in absence of annotation), the type accepted by a pattern is the
gradual type.

### Typing rules

The judgement $\Gamma \tinfer e : \τ$ corresponds to the inference system and
the judgement $\Gamma \tcheck e : \τ$ to the check system.
The notation $\Gamma \tIC e : \τ$ means either $\Gamma \tinfer e : \τ$ or
$\Gamma \tcheck e : \τ$ (but always the same in a given inference rule).

The rules for both systems are given in the
figure \pref{typing::lambda-calculus}.

#### Constants and variables

\newcommand{\Bt}{\mathcal{B}}
We assume the existence of a function $\Bt$ which associates to each constant
$c$ its type $\Bt(c)$.

#### Lambda-abstractions

The arguments have to be annotated explicitly (or `?` is assumed). Thus the
inference of an abstraction is rather simple.

The check is somehow more complex. The idea is that to check that an expression
$λ p.e$ admits the type $\τ$ under the hypothesis $\Gamma$ we must check
that each arrow type $\sigma_1 \rightarrow \sigma_2$ "contained" in $\τ$ is
admitted by the expression, which means that under the hypothesis $\Gamma;
\tmatch{\sigma_1}{p}$, $e$ admits the type $\sigma_2$.

\newcommand{\A}{\mathcal{A}}
The notion of "containment" is given by the $\A$ operator defined as follows
for a type $\τ$ subtype of `Empty -> Any`:

If $\τ$ is of the form

\begin{displaymath}
  \tau = \bigvee\limits_{i\in I}\left(
    \bigwedge\limits_{p\in P_i} (\sigma_p \rightarrow \tau_p)
    \wedge \bigwedge\limits_{n \in N_i} \lnot (\sigma_n \rightarrow \tau_n)
  \right)
\end{displaymath}

then $\A(\tau)$ is define as

\begin{displaymath}
  \A(\tau) = \bigsqcup\limits_{i \in I} \{ \sigma_p \rightarrow \tau_p | p \in P_i \}
\end{displaymath}

where $\sqcup$ is itself defined as

\begin{displaymath}
  \{ \sigma_i \rightarrow \tau_i \| i \in I \} \sqcup \{ \sigma_j \rightarrow \tau_j \| j \in J \} =
    \{ (\sigma_i \wedge \sigma_j) \rightarrow (\tau_i \vee \tau_j) \| i \in I, j \in J \}
\end{displaymath}

@Fri04 shows that $\τ$ can always be expressed in previous form (in fact this
possibility is fundamental for the sybtyping algorithm as shown by @Cas15).

In the example of section \ref{typing::lambda-calculus::general-description}
the type $\τ$ is equal to `(true -> Int -> Int) AND (false -> Bool -> Bool)`,
so $\A(\tau)$ is the set $\{$ `true -> Int -> Int`; `false -> Bool -> Bool` $\}$.

#### Application

\newcommand{\dom}{\tilde{\operatorname{Dom}}}
\newcommand{\image}{\tilde{\circ}}

The inference rule for the application is different from the one used in simply
typed lambda-calculus: Because of the presence of union and intersection types,
the types of functions aren't simply arrow types, but are all the subtypes of
the `Empty -> Any` type.
As consequence, the definitions of the domain and image of such function
types is more complex.

We reuse the definitions of the $\dom$ and $\image$ operators defined by @CL17.
The intuition for those operators is that $\dom(\τ)$ is the domain of the
functions of type $\τ$ and $\τ \image \sigma$ is the image by $\τ$ of all the
elements of type $\sigma$.
For example, $\dom(\τ_1 \rightarrow \sigma_1 \wedge \τ_2 \rightarrow \sigma_2)$ is
$\τ_1 \vee \τ_2$, and $(\τ_1 \rightarrow \sigma_1 \wedge \τ_2 \rightarrow
\sigma_2) \image \τ_1$ is $\sigma_1$.
Once those operators are defined, the inference rule for the application is
rather straightforward.

The check rule is simpler, but requires using the inference system, as the type
of the argument is unknown.
Hence, to check that $\Gamma \tcheck e_1 e_2 : \τ$, we first infer the type
$\sigma$ of $e_2$, and then we check that $e_1$ has type $\sigma \rightarrow
\τ$.
We also could imagine first inferring the type $\τ'$ of $e_1$, and then
try to calculate the preimage $\sigma'$ of $\τ$ by $\τ'$ and check that $e_2$
has type $\sigma'$. However, this approach is more complicated (it is unsure
whether there is an easy way to calculate this preimage) and probably less
useful in practice (as inferring the type of functions is often the difficult
part while checking it is easier).

#### Let-bindings

The let-bindings are the places where the system goes from inference to
checking: for each variable that is being defined, if it is annotated, then we
check that its definition has the right type (else we simply infer the type of
its definition).
As let-bindings are recursive and no unification is made, the non-annotated
variables must be given a default type to type the definitions. The chosen type
is `?` (although choosing `Any` instead is an equally reasonable choice, simply
more restrictive).
This rule has the advantage of being quite general. In particular it can type
non-recursive let-bindings without requiring annotations and without loss of
precision.

#### Typecase

The typing of the typecase uses what @FH08 call "occurrence typing".
This means that when typing the expression `(x = e tin t) ? e1 : e2`, the type
of `x` will be refined in each branch: it will be assumed of type `$t_e$ AND t`
in `e1` and of type `$t_e$ AND $\lnot$t` in `e2` (where `$t_e$` is the type of
`e`).
Moreover, if the system infers that `e` is always of type `t` (or `$\lnot$t`),
then the dead branch doesn't need to be typed.
This is what the two implications in the inference rule express: If one of the
two conditions will never be met (or both), then there is no need to type the
corresponding branch.
This particular characteristic may seem undesirable (as it in particular that
an expression may be well-typed while some of its sub-terms aren't), but the
need for it is clear if we once again consider the example of
section \label{typing::lambda-calculus::general-description}.
Indeed, we want the body of the function to be well-typed under the hypothesis
`cond: True; x : Int`, while `not x` isn't (but is never reached under those
hypothesis).
One last particularity is that both branches may have different types, the
final type being the union of them.
This is natural if we consider the fact that the inference may be too precise
in both branches and return types that both are subtypes of the expected return
type.
For example, we want to accept the expression `(x = e tin t) ? 1 : 2` while the
system will infer the type `1` for the first branch and `2` for the second.
Of course, the drawback is that the inference never fails and may lead to type
errors that are thrown far away from the actual error.

The check works the same way, except that we can directly check the same type
for both branches. Note that we have to infer the type of the tested
expression as we can't know it in advance.

\input{typing/lambda-inference-rules.tex}
